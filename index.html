<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Main Step: Edit below title -->
    <title>TODO: Paper Title</title>

    <!-- SEO Meta Tags -->
    <meta name="description" content="" />
    <meta
      name="keywords"
      content="research papers, academic papers, AI research, robotics research, machine learning, published papers, scientific papers, academic journals"
    />
    <!-- <meta name="author" content="Research Paper Platform" />
    <meta name="robots" content="index, follow" />
    <meta
      name="robots"
      content="max-snippet:-1, max-image-preview:large, max-video-preview:-1"
    /> -->

    <!-- Open Graph Meta Tags (For Social Media Sharing) -->
    <!-- <meta
      property="og:title"
      content="Research Papers - Explore Cutting-Edge Research"
    />
    <meta
      property="og:description"
      content=""
    />
    <meta property="og:image" content="path-to-your-image.jpg" />
    <meta property="og:url" content="https://www.yourwebsite.com" />
    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="Research Paper Platform" /> -->

    <!-- Twitter Meta Tags (For Twitter Sharing) -->
    <!-- <meta
      name="twitter:title"
      content="Research Papers - Explore Cutting-Edge Research"
    />
    <meta
      name="twitter:description"
      content=""
    />
    <meta name="twitter:image" content="path-to-your-image.jpg" />
    <meta name="twitter:card" content="summary_large_image" /> -->

    <!-- Canonical Link -->
    <!-- <link rel="canonical" href="https://www.yourwebsite.com" /> -->

    <!-- Favicon for different platforms -->
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-16.png"
      sizes="16x16"
      type="image/png"
    />
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-32.png"
      sizes="32x32"
      type="image/png"
    />
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-70.png"
      sizes="70x70"
      type="image/png"
    />
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-72.png"
      sizes="72x72"
      type="image/png"
    />
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-96.png"
      sizes="96x96"
      type="image/png"
    />

    <link rel="stylesheet" type="text/css" href="style.css" />
  </head>
  <body>
    <nav class="nav">
      <a href="#abstract">Abstracto</a>
      <a href="#introduction">Introducción</a>
      <a href="#methodology">Metodología</a>
      <a href="#results">Resultados y análisis</a>
      <a href="#conclusion">Conclusiones</a>
      <button class="toggle-btn" onclick="toggleDarkMode()">
        Modo oscuro
      </button>
    </nav>

    <!-- Step 1 Start: Header Part -->

    <!-- 
    Remove if not applicable
    Edit below todo text
    Add URL link by removing # for each authers. Link can be GitHub, LinkedIn, Google Schooler, Website or other
    -->

    <div class="header">
      <h1>Paper Title</h1>
      <div class="authors">
        <p>
          <a href="#">Ignacio Nicolas Passerini Terranova</a>
        </p>
        <p>
          <a>Universidad Nacional de Tres de Febrero</a> | <a href="">Intercambios Transorgánicos</a></p>
        <p>
          <a href="mailto:ignaciopasser@gmail.com">ignaciopasser@gmail.com</a>
        </p>
      </div>
    </div>

    <!-- Step 1 End: Header Part -->
    <!-- Step 2 Start: Button for links -->

    <!-- 
    Add URL links for each buttons according to name mentioned
    Remove # and add the link
    Add new button link if required
    Remove this step if not applicable
    -->

    <!-- <div class="buttons">
      <a href="#" target="_blank">Videos</a>
      <a href="#" target="_blank">Código</a>
    </div> -->

    <!-- Step 2 End: Button for links -->

    <!-- Step 3 Start: Add your paper abstract -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <!-- Single YouTube Video -->
    <!-- <div class="video-section">
      <h3>Demo Video</h3>
      <div class="video-container">
        <iframe
          width="560"
          height="315"
          src="https://www.youtube.com/embed/ysFav0b472w?si=Rxxp3R6_tkBXAEmP"
          title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          referrerpolicy="strict-origin-when-cross-origin"
          allowfullscreen
        ></iframe>
      </div>
      <p>
        TODO: This is the short explanation paragraph of the video. Add your
        paragraph here if required
      </p>
    </div> -->

    <div class="abstract" id="abstract">
      <h2>Abstracto</h2>
      <p>Este artículo describe el diseño de una grabadora de voz orientada a la recolección de muestras del español hablado en Argentina, con el objetivo de crear un corpus representativo del español hablado en Argentina. El diseño de la herramienta se realizó bajo un enfoque basado en los principios de la Interacción Humano-Computadora (HCI), asegurando que la interfaz y la experiencia de usuario fueran accesibles, intuitivas y eficaces. Además se priorizó la captura fiel de la voz natural de los usuarios, respetando su tono, acento y ritmo. Como resultado, esta herramienta garantiza una recolección de voz inclusiva y fiel a las características naturales del hablante. Ideal para investigaciones lingüísticas como para el desarrollo de tecnologías del habla adaptadas al contexto argentino.
       <strong>Keywords</strong>: Human-Computer Interaction, Experiencia de usuario, Recolección de voces, Diseño web, Dialecto argentino.
      </p>
    </div>

    <!-- Step 3 End: Add your paper abstract -->

    <!-- Step 4 Start: Add your paper introduction -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <div class="content-section" id="introduction">
      <h2>Introducción</h2>
      <p>El español hablado en Argentina presenta una gran diversidad de acentos y variaciones lingüísticas, lo que hace fundamental la creación de un corpus de voz representativo y de alta calidad para su estudio y aplicaciones tecnológicas. Si bien existen diversas herramientas en la web para la grabación y recopilación de voz, la mayoría se limita a funciones básicas como permitir la grabación y descarga de audios, sin considerar particularidades lingüísticas ni principios de diseño centrados en el usuario. Incluso iniciativas como CommonVoice, que buscan construir un corpus de voces de múltiples idiomas mediante colaboración masiva (Ardila et al., 2019), aunque bien implementadas desde la perspectiva de la Interacción Humano-Computadora (HCI), no están específicamente adaptadas al español argentino ni optimizan la cobertura fonética del dialecto local. Tampoco incorporan estrategias para mantener la motivación del usuario durante la grabación, lo que puede afectar la continuidad de la participación.
        
        En este trabajo se propone el diseño de una grabadora de voz especialmente pensada para recolectar muestras del habla argentina. Basada en principios de Interacción Humano-Computadora (HCI), se busca crear una herramienta intuitiva, accesible y eficaz, que pueda ser utilizada por personas de todas las edades y niveles de experiencia tecnológica, incluyendo adultos mayores o usuarios con escaso manejo de computadoras. Además, se prioriza la captura de la voz en su forma más natural —en tono, acento y ritmo— asegurando que las muestras sean lo más representativos posible de la voz real de cada hablante, respetando su naturalidad y características propias. Esto permitirá construir un corpus más representativo de las particularidades del español hablado en Argentina, con potencial de impacto tanto en la investigación lingüística como en el desarrollo de tecnologías del habla adaptadas a nuestra región.
        
        Para el desarrollo de esta herramienta, se adoptó un enfoque iterativo basado en el ciclo de diseño de software del modelo de Norman. En una primera etapa, se evaluó la interfaz original identificando oportunidades de mejora desde la perspectiva de la Interacción Humano-Computadora (HCI). A partir de ese análisis, se diseñó un prototipo de baja fidelidad orientado a resolver los problemas detectados, con especial énfasis en la usabilidad, accesibilidad y facilidad de interacción, buscando garantizar una experiencia intuitiva para todo tipo de usuarios.
        
        Este prototipo fue evaluado mediante pruebas de usabilidad con usuarios potenciales, lo que permitió detectar nuevas necesidades y áreas de mejora. En base a esos resultados, se desarrolló una segunda versión del prototipo, que también fue sometida a evaluación. Dado que el prototipo cumplía con los objetivos establecidos y no se identificaron inconvenientes relevantes, se avanzó con el desarrollo del prototipo de alta fidelidad.
        
        <strong>Pregunta de investigación</strong>: ¿De qué manera puede un enfoque basado en la Interacción Humano-Computadora (HCI) mejorar la accesibilidad y usabilidad de una grabadora de voz destinada a construir un corpus representativo del español hablado en Argentina?
      </p>
    </div>

    <div class="content-section" id="estado">
      <h2>Estado del arte</h2>
      <p>Existen numerosas herramientas orientadas a la grabación y descarga de audios con fines generales, como Voice Recorder, Clipchamp, Capcut, Vocaroo, Clyp, Speakpipe y Audiopal. Estas plataformas, si bien son funcionales, no están diseñadas para la creación de corpus lingüísticos ni contemplan aspectos como la diversidad dialectal o la experiencia del usuario. En contraste, existen iniciativas específicamente orientadas a la construcción de corpus de voz, como VoxForge (VoxForge, 2025), CommonVoice (Ardila et al., 2019) y LinguaLibre (LinguaLibre, 2025) que buscan recolectar grandes volúmenes de datos mediante colaboración masiva. Sin embargo, cada una presenta limitaciones específicas en relación a los objetivos de este trabajo.
        
        CommonVoice no adapta los textos al español argentino, ni busca optimizar la cobertura fonética del dialecto local. Tampoco incorpora estrategias para mantener el interés o la motivación del usuario durante la grabación, lo cual puede afectar la continuidad de la participación.
        
        LinguaLibre, por otro lado, se enfoca únicamente en la grabación de palabras sueltas, lo que dificulta construir un corpus con entonación y ritmo natural del habla continua.
        
        VoxForge no ofrece una plataforma de grabación integrada, por lo que el usuario necesita usar programas externos para grabar, lo que puede ser una dificultad para quienes no tienen experiencia técnica. 
        
        A diferencia de las propuestas existentes, esta herramienta fue desarrollada bajo un enfoque centrado en los principios de la Interacción Humano-Computadora (HCI), priorizando tanto la experiencia del usuario como la calidad lingüística de las grabaciones. En este sentido, se diseñaron textos específicos para el español argentino que buscan maximizar la variedad fonética y mantener el interés durante la tarea. Además, se eliminó la posibilidad de prelectura y relectura, con el fin de evitar una pronunciación ensayada y garantizar que las grabaciones representen con mayor precisión el habla natural del usuario. 
      </p>
    </div>

    <div class="content-section" id="marco">
      <h2>Marco teórico</h2>
      <ol type="a">
        <li>
          <strong>Interacción Humano-Computadora</strong>
          <p>La interacción humano-computadora es una disciplina que se ocupa del diseño, la evaluación y la implementación de sistemas informáticos interactivos para el uso humano, así como del estudio de los principales fenómenos que los rodean (Hewett et al. 1992). El objetivo principal de incorporar características de HCI en el diseño es desarrollar interfaces de usuario eficientes y efectivas que se ajusten a los requerimientos y deseos de los usuarios. Para lograrlo, se debe establecer un diseño de interfaz adecuado, que permita al usuario interactuar y navegar con facilidad, otorgándole mayor control sobre el sistema. (Sustainable Design).
            
            Entre sus principios se encuentran la usabilidad y accesibilidad. La usabilidad busca que los usuarios puedan interactuar de forma simple, efectiva y con bajo esfuerzo cognitivo. Para lograrlo, se aplican metodologías como pruebas con usuarios, evaluaciones heurísticas y diseño iterativo. Por otro lado, la accesibilidad está orientada a garantizar el uso del sistema por personas con distintas capacidades y niveles de experiencia tecnológica. En este caso se aplican principios de diseño inclusivo para que los sistemas sean accesibles para personas con discapacidades visuales, auditivas, motrices o cognitivas. (Human-Computer Interaction: Enhancing User Experience in Interactive Systems).
            
            Esta disciplina también considera factores como el diseño visual y la satisfacción emocional. Una interfaz atractiva motiva a los usuarios a continuar la interacción. Para ello se aplican conceptos como jerarquía visual, la teoría del color y la tipografía para crear interfaces intuitivas, atractivas y coherentes en lo visual. (Human-Computer Interaction: Enhancing User Experience in Interactive Systems).
            
            Aplicar los principios de HCI en el desarrollo de una herramienta de recolección de voz permite no solo mejorar la experiencia del usuario, sino también garantizar la precisión de los datos recolectados, ya que una interfaz clara y comprensible facilita un uso correcto y consistente del sistema.
          </p>
        </li>
        <li>
          <strong>Ciclo de vida del diseño de experiencia de usuario</strong>
          <p>El ciclo de vida del diseño de experiencia de usuario (UX), según Hartson y Pyla (2019), es un proceso de diseño de experiencia de usuario iterativo y centrado en la evaluación continua. Este modelo nace de la relación entre la interacción humano-computadora (HCI) y el diseño UX, donde se emplean principios y métodos de HCI para comprender al usuario, sus necesidades y la manera en que interactúa con la tecnología. A partir de este entendimiento, se diseñan experiencias, se construyen prototipos, se evalúan mediante diversas técnicas, y los resultados se retroalimentan al proceso para refinar tanto el diseño como el conocimiento sobre la interacción. El ciclo se repite hasta lograr una interfaz que maximice la calidad de la experiencia. En vez del modelo clásico en cascada, este modelo actúa como una rueda en donde cada rotación te acerca más a tu destino, una mejor experiencia de usuario. 
            
            Se divide en cuatro etapas fundamentales:
          </p>
          <ul>
            <li>
              <strong>Needfinding</strong><p>En la búsqueda de necesidades (Needfinding), se analiza qué es lo que el usuario desea. Se busca comprender las tareas que los usuarios intentan realizar. Esto incluye identificar quién es el usuario, cuál es el contexto de la tarea, por qué está llevando a cabo dicha tarea y cualquier otra información relacionada con lo que se está diseñando. El proceso comienza definiendo algunas preguntas generales que se desean responder a lo largo de la recopilación de datos sobre quién es el usuario, qué está haciendo y qué necesita. Luego, se emplean diversos métodos para generar respuestas a esas preguntas y así obtener una mejor comprensión del usuario. Posteriormente, se aborda la formalización de los datos recopilados en un modelo compartible de la tarea y una lista de requisitos para la interfaz final.</p>
            </li>
            <li>
              <strong>Alternativas de diseño</strong><p>Se desarrollan múltiples alternativas de diseño para evitar quedarnos atascados en una sola idea demasiado pronto. El objetivo es explorar una variedad de posibilidades antes de converger en una solución final que ofrezca una experiencia de usuario de alta calidad.</p>
            </li>
            <li>
              <strong>Prototipado</strong><p>Se toman las ideas con más potencial y se transforman en prototipos que luego pueden presentarse a los usuarios. El objetivo es crear representaciones tangibles de las ideas de diseño para explorar, comunicar y evaluar soluciones antes de su implementación final. Los prototipos varían en niveles de fidelidad, que incluyen baja fidelidad (como prototipos en papel, tales como impresiones de wireframes estáticos, utilizados para la exploración del diseño y revisiones tempranas), fidelidad media (como prototipos interactivos de wireframes con navegación mediante clics) y alta fidelidad (prototipos funcionales programados).</p>
            </li>
            <li>
              <strong>Evaluación</strong><p>Se evalúa la usabilidad, accesibilidad y experiencia general de cada prototipo, entrevistando a usuarios. Hay muchas formas de evaluar interfaces, se dividen en tres categorías:</p>
              <ul>
                <li>
                  <p>Evaluación cualitativa: evaluación que enfatiza la totalidad del fenómeno. Se busca saber que aspectos les gusto o no les gusto a los usuarios, que estaban pensando mientran usaban la interfaz, por qué realizaron cierta acción, etc.</p>
                </li>
                <li>
                  <p>Evaluación empírica: evaluación basada en resúmenes numéricos u observaciones de un fenómeno. Obtenemos feedback cuantitativo realizando experimentos controlados y evaluando los resultados. Esto lo debemos hacer luego de obtener el feedback cualitativo y requerimos de múltiples usuarios.</p>
                </li>
                <li>
                  <p>Evaluación predictiva: evaluación basada en una aplicación sistematizada de principios y heurísticas preestablecidas. Es evaluar sin usuarios.</p>
                </li>
              </ul>
            </li>
          </ul>
            
        </li>
        <li>
          <strong>Affordances</strong>
          <p>Una affordance puede definirse como una relación entre las propiedades de un objeto y las capacidades del usuario que determinan cómo podría utilizarse dicho objeto (Norman, 1988). Una silla, por ejemplo, ofrece soporte y, por lo tanto, permite sentarse. La existencia de una affordance depende tanto de las propiedades del objeto como de las capacidades perceptuales y motrices del usuario. En el contexto del diseño de experiencia de usuario (UX), esta definición ha sido ampliada: una affordance es todo aquello que permite al usuario hacer o sentir algo durante su interacción con un sistema (Hartson & Pyla, 2019).
            En esta línea, los autores identifican cinco tipos de affordances, cada uno con un rol particular en la facilitación de la interacción.
          </p>
          <ul>
            <li>
              <u>Affordance cognitivo</u>: Característica de diseño que ayuda a los usuarios con sus acciones cognitivas: pensar, decidir, aprender, recordar y conocer cosas. Un ejemplo sería una etiqueta en un botón que ayuda a los usuarios a saber qué sucederá si hacen clic en él.
            </li>
            <li>
              <u>Affordance física</u>: Característica de diseño que ayuda a los usuarios con sus acciones físicas: hacer clic, tocar, señalar, gesticular y mover cosas. Un ejemplo sería un botón lo suficientemente grande para que los usuarios puedan hacer clic en él con precisión.
            </li>
            <li>
              <u>Affordance sensorial</u>: Característica de diseño que ayuda a los usuarios con sus acciones sensoriales: ver, oír y sentir (además de saborear y oler). Un ejemplo sería un tamaño de fuente lo suficientemente grande para ser legible.
            </li>
            <li>
              <u>Affordance funcional</u>: Característica de diseño que ayuda a los usuarios a utilizar un producto o sistema para realizar un trabajo (es decir, la utilidad de una función del sistema). Un ejemplo sería la capacidad del sistema para ordenar una serie de números cuando los usuarios hacen clic en el botón "Ordenar".
            </li>
            <li>
              <u>Affordance emocional</u>: Característica de diseño que añade impacto emocional a la experiencia del usuario y ayuda a que aprecien y disfruten la interacción. Un ejemplo sería la estética atractiva en una página web, algo que haga que la interacción sea divertida.
            </li>
          </ul>
          <p>Un enfoque integral de diseño UX debe contemplar la combinación de estos cinco tipos de affordances al diseñar un artefacto de interacción. Este término engloba sistemas, dispositivos, servicios, objetos o entornos que establecen comunicación, en una o ambas direcciones, con los seres humanos.</p>
        </li>
      </ol>
    </div>
    <!-- Step 4 End: Add your paper introduction -->

    <!-- Step 5 Start: Add your paper methodology -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <div class="content-section" id="methodology">
      <h2>Metodología</h2>
      <p>Previo al presente trabajo, el equipo de desarrollo había diseñado una primera versión de la interfaz para la grabadora de voz sin seguir ninguna metodología formal de diseño centrada en el usuario. Esta versión inicial fue construida de manera intuitiva, priorizando la funcionalidad básica y asumiendo que el usuario recibiría instrucciones a través de un video explicativo. En consecuencia, aspectos fundamentales como la usabilidad, accesibilidad y experiencia de usuario no fueron considerados en profundidad durante esta etapa.
        
        A partir del estudio de los principios de la Interacción Humano-Computadora (HCI), se llevó a cabo un análisis crítico del diseño original, identificando sus principales deficiencias desde una nueva perspectiva centrada en el usuario. Sobre esta base, se desarrolló un prototipo de baja fidelidad orientado a resolver los problemas detectados, incorporando principios de diseño HCI con el objetivo de mejorar la usabilidad y facilitar la interacción, independizando la interfaz del video explicativo. En la siguiente sección se detallan los problemas identificados en el diseño original, así como las soluciones propuestas en el primer prototipo. 
      
      </p>
      <div class="image-section">
        <img src="Assets/Figura1.jpg" alt="">
        <p><strong>Figura 1: </strong>Etapa de pre-grabación del diseño original.</p>
      </div>
      <p>Esta pantalla representa el primer paso del ciclo de grabación. Fue diseñada con el objetivo de brindarle al usuario un momento de preparación cognitiva, en el que pueda leer y comprender el texto que va a grabar. Reduce la carga cognitiva al permitir que la grabación no lo tome por sorpresa ni lo obligue a improvisar.

      El ítem (1) es un menú desplegable (select) que le permite al usuario seleccionar el autor de los textos que va a leer. El problema es que este enfoque fue descartado, la selección de textos literarios no garantizaba una buena cobertura fonológica (es decir, variedad de sonidos del habla), lo cual es un objetivo central del sistema. Debido a ello, se diseñaron frases especialmente construidas para maximizar la presencia de distintos fonemas del español argentino. Entonces, este selector debe ser eliminado ya que su presencia es innecesaria. 

      El ítem (3) es un bloque de texto que tiene como propósito anticipar el contenido que se grabará en el siguiente paso. Esta presentación anticipada actúa como una estrategia de diseño que promueve la preparación mental (affordance cognitivo) y ayuda a reducir errores durante la grabación. Como se indicó previamente, el problema de este ítem es que los textos no garantizan la cobertura de todos los fonemas posibles por lo deben ser sustituidos por frases ingeniadas para la recolección de fonemas. 

      El ítem (2) es el botón de inicio de grabación. Contiene el símbolo de un micrófono que actúa como un affordance cognitivo ya que es un símbolo ampliamente reconocido en contextos digitales y comunica de forma inmediata la funcionalidad de “grabar audio”.  El botón también es un affordance físico debido a que el botón tiene un tamaño y forma adecuados para interfaces táctiles, lo que permite que el usuario lo presione con facilidad. Y es un affordance sensorial gracias a que el alto contraste visual entre el botón y el fondo, y su ubicación destacada en la esquina superior derecha, mejoran su visibilidad. No presenta ningún problema de diseño.

      </p>
      <div class="image-section">
        <img src="Assets/Figura2.jpg" alt="">
        <p><strong>Figura 2: </strong>Etapa de pre-grabación del prototipo de baja fidelidad.</p>
      </div>
      <p>El ítem (1) es el botón de inicio de grabación. Este presenta una diferencia clave respecto al diseño original, el micrófono fue reemplazado por un nuevo ícono compuesto por un triángulo y un cuadrado. Esta decisión tuvo como objetivo evaluar si los usuarios asociaban correctamente estos símbolos a la acción de avanzar o retroceder de paso. Esta no sería la primera vez que ven este símbolo ya que, como se contará más adelante, se agregaron pasos extras previos al inicio del ciclo de grabación donde este icono está presente.

        El ítem (2), que anteriormente era un menú desplegable para seleccionar el autor del texto, fue reemplazado por un contador de audios enviados. Dicho contador también se encuentra en uno de los siguientes pasos pero se decidió incluir también en esta pantalla por el principio de flexibilidad: para beneficiar a los usuarios más experimentados, que suelen interactuar rápidamente con la interfaz y podrían no llegar a revisar este dato en pasos posteriores, lo cual podría generar confusión o frustración si no tienen claridad sobre su progreso.

        Del ítem (3) reemplazaron los fragmentos de obras literarias por frases diseñadas específicamente para cubrir la mayor diversidad de fonemas del español. Esta modificación permite mejorar la calidad de los datos recogidos sin comprometer la comprensión lectora del usuario.

      </p>
      <div class="image-section">
        <img src="Assets/Figura3.jpg" alt="">
        <p><strong>Figura 3: </strong>Etapa de grabación del diseño original.</p>
      </div>
      <p>Este es el segundo paso del ciclo de la grabación. Durante esta etapa, el usuario grabará su voz leyendo el texto que se muestra en pantalla. 

        El ítem (1) es el botón de finalización de grabación. El botón de inicio de grabación cambia visualmente luego de ser activado, transformándose en un círculo rojo con un cuadrado blanco. Este símbolo se eligió porque es reconocido y asociado culturalmente con la acción de "detener grabación". Este botón representa un affordance cognitivo, ya que informa mentalmente al usuario sobre su función esperada. Al igual que el botón de inicio de grabación, es un affordance físico y sensorial. La diferencia es que este botón es aún más visible ya que el color rojo atrae rápidamente la atención. No presenta ningún problema de diseño.
        
        El resto de ítems mantienen los problemas descritos anteriormente.

        El problema de este diseño es que si bien el ícono es culturalmente reconocible, no hay otros que indiquen de forma explícita que la grabación está en curso. Esto puede generar incertidumbre en el usuario, especialmente si no está familiarizado con este tipo de interfaz.

      </p>
      <div class="image-section">
        <img src="Assets/Figura4.jpg" alt="">
        <p><strong>Figura 4: </strong>Etapa de grabación del prototipo de baja fidelidad.</p>
      </div>
      <p>El ítem (1) se mantuvo igual.

      El ítem (2) anteriormente correspondía al selector de autor. En esta etapa fue reemplazado por un cronómetro que indica la duración actual de la grabación en curso. Este elemento fue introducido como un affordance cognitivo: su presencia transmite de manera inmediata al usuario que está grabando.

      El ítem (3) es otro botón para finalizar la grabación. Este nuevo botón, ubicado debajo del cuadro de texto, fue incorporado con un propósito evaluativo: se pretende comparar su eficacia frente al botón tradicional con ícono. La inclusión de la etiqueta textual "Finalizar grabación" busca maximizar claridad y minimizar la ambigüedad.

      </p>
      <div class="image-section">
        <img src="Assets/Figura5.jpg" alt="">
        <p><strong>Figura 5: </strong>Etapa de evaluación del diseño original.</p>
      </div>
      <p>Esta es la tercera etapa del ciclo de grabación y corresponde a la evaluación de la grabación realizada. El usuario evaluará el resultado y decidirá si enviarlo o borrarlo.

      El ítem (1) mantiene el problema anteriormente mencionado.

      El ítem (2) es el botón de inicio de grabación desactivado. La capa color gris sobre este actúa como un affordance cognitivo, es una convención visual ampliamente reconocida en interfaces digitales que le indica al usuario que la función está temporalmente deshabilitada o no disponible en este momento. El botón es percibido como apagado.

      El problema de estos dos ítems es que no son necesarios, se pueden remover por completo para reducir la carga cognitiva y eliminar distracciones.

      El item (3) es un conjunto compuesto por el audio resultante, los botones para enviar o borrar grabación y el contador de audios enviados. El reproductor fue construido a partir del diseño convencional de un reproductor de audio, actuando como un affordance cognitivo. Se utilizaron colores convencionales (verde para enviar, rojo para borrar) como affordances cognitivos y emocionales, que comunican claramente la naturaleza y consecuencias de las acciones. El color verde está culturalmente asociado con avanzar o confirmar mientras que el color rojo está culturalmente asociado a detener o eliminar. El tacho de basura y el símbolo de tilde son iconos culturalmente reconocidos que también ayudan a reforzar estas ideas. Finalmente, las etiquetas “Enviar” y “Borrar” indican explícitamente la funcionalidad de cada botón. El único problema con este ítem es el título “GRABACIÓN” que es ambiguo.

      </p>
      <div class="image-section">
        <img src="Assets/Figura6.jpg" alt="">
        <p><strong>Figura 6: </strong>Etapa de evaluación del prototipo de baja fidelidad.</p>
      </div>
      <p>Siguiendo el principio de simplicidad, se eliminaron los ítems (1) y (2) de esta etapa. Además se reemplazó la etiqueta “GRABACIÓN” por “¿Querés escuchar tu grabación?” que es una pregunta directa que invita al usuario a realizar una acción específica.</p>
      <div class="image-section">
        <img src="Assets/Figura7.jpg" alt="">
        <p><strong>Figura 7: </strong>Contexto sobre Archivoz.</p>
      </div>
      <div class="image-section">
        <img src="Assets/Figura8.jpg" alt="">
        <p><strong>Figura 8: </strong>Indicaciones que el usuario debe seguir durante el proceso.</p>
      </div>
      <p>Finalmente, se ideó una manera de poder proporcionarle al usuario las indicaciones que debe que tener en cuenta durante la donación de audios, sin necesidad de mirar un video explicativo, lo que viola el principio de detectabilidad. Se agregaron pasos previos al inicio del proceso.

        En la figura 7 se introduce brevemente el propósito del sistema y se contextualiza la participación del usuario. Si bien esta etapa puede considerarse redundante en el producto final (donde se espera que el usuario ya esté informado sobre el objetivo del sistema), fue incluida en en este prototipo para facilitar la comprensión durante las entrevistas.

        La figura 8 contiene instrucciones sobre cómo realizar la lectura del texto. Se hace énfasis en la necesidad de una lectura fluida y natural, e incluye pautas explícitas sobre qué hacer en caso de cometer errores (borrar la grabación y continuar con otra).

        Ambos pasos cuentan con un overlay gris sobre la fase inicial del ciclo de grabación que actúa como un affordance cognitivo comunicando de manera implícita que el resto del sistema no está disponible en ese momento. Además cuentan con botones para avanzar o retroceder un paso, cuyo diseños contienen una flecha que actúa como un affordance cognitivo indicando la dirección en la que el usuario se moverá.
        
      </p>
      <div class="image-section">
        <img src="Assets/Figura9.jpg" alt="">
        <p><strong>Figura 9: </strong>Indicaciones para prueba de audio.</p>
      </div>
      <div class="image-section">
        <img src="Assets/Figura10.jpg" alt="">
        <p><strong>Figura 10: </strong>Prueba de audio.</p>
      </div>
      <p>Como paso adicional previo al inicio del ciclo de grabación, se incorporó una etapa de verificación del funcionamiento del micrófono. Aunque esta funcionalidad no es necesaria en entrevistas presenciales o controladas, se incluyó para simular la experiencia completa que tendría un usuario real al utilizar la plataforma de forma autónoma.

      En la figura 9 se presenta un mensaje breve que informa al usuario que está a punto de grabar un fragmento de 10 segundos con el objetivo de calibrar el audio. Esto permite que se prepare antes de comenzar.

      En la figura 10, se muestra un texto de prueba que el usuario debe leer en voz alta. Esta etapa tiene una duración fija de 10 segundos. Al completarse el tiempo, el sistema transiciona automáticamente al primer paso del ciclo de grabación principal, eliminando la necesidad de interacción manual.
      </p>
      <h3>A partir de acá, comenzaré a hablar de las entrevistas que realizamos.</h3>
    </div>

    <!-- Step 5 End: Add your paper methodology -->

    <!-- Step 6 Start: Add your paper results -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    Below have pre-build code for:
    -> 3 Images Carousel
    -> 3 Videos Carousel
    -> Single YouTube Video
    -> YouTube Video List
    If you do not need those, remove them.
    How to add YouTube Video:
    -> Go to the video page
    -> Click Share Button and Click <> Mark
    -> This will give <iframe></iframe> tag code
    -> Replace below <iframe></iframe> tag with your code
    -->

    <div class="content-section" id="results">
      <h2>Resultados y análisis</h2>
      <p>TODO: Add Results</p>
      <ul>
        <li>TODO</li>
        <li>TODO</li>
      </ul>
    </div>

    <!-- 3 Images Carousel -->
    <!-- <h3>Image Gallery</h3>
    <div class="carousel-container" id="imageCarousel">
      <div class="carousel-track">
        <div class="carousel-slide">
          <img src="Assets/Photo1.jpg" alt="Slide 1" />
        </div>
        <div class="carousel-slide">
          <img src="Assets/Photo2.jpg" alt="Slide 2" />
        </div>
        <div class="carousel-slide">
          <img src="Assets/Photo3.jpg" alt="Slide 3" />
        </div>
        <div class="carousel-slide">
          <img src="Assets/Photo4.jpg" alt="Slide 4" />
        </div>
        <div class="carousel-slide">
          <img src="Assets/Photo5.jpg" alt="Slide 5" />
        </div>
        <div class="carousel-slide">
          <img src="Assets/Photo6.jpg" alt="Slide 6" />
        </div>
        <div class="carousel-slide">
          <img src="Assets/Photo7.jpg" alt="Slide 7" />
        </div>
        <div class="carousel-slide">
          <img src="Assets/Photo8.jpg" alt="Slide 8" />
        </div>
      </div>
      <button class="carousel-button prev">←</button>
      <button class="carousel-button next">→</button>
      <div class="carousel-indicators"></div>
    </div> -->

    <!-- 3 Videos Carousel -->
    <!-- <h3>Video Gallery</h3>
    <div class="carousel-container" id="videoCarousel">
      <div class="carousel-track">
        <div class="carousel-slide">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/Bhg3uOx9ZPw?si=4Ie__ntcTSvRRi4y"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen
          ></iframe>
        </div>
        <div class="carousel-slide">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/xjRALKy6Ajw?si=EMrMe_v9fXOjhi_J"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen
          ></iframe>
        </div>
        <div class="carousel-slide">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/aaTUS5Aa8F0?si=NUvuwq8-SzC5RuqQ"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen
          ></iframe>
        </div>
        <div class="carousel-slide">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/JficcrhnO78?si=8SryP_KFQ0orNyMt"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen
          ></iframe>
        </div>
        <div class="carousel-slide">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/kEdr0ARq48A?si=ADLxnzCBkTDQm28o"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen
          ></iframe>
        </div>
        <div class="carousel-slide">
          <iframe
            width="560"
            height="315"
            src="https://www.youtube.com/embed/v_ulHMfDUco?si=0fJGN4AmWj_zP-Ik"
            title="YouTube video player"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen
          ></iframe>
        </div>
      </div>
      <button class="carousel-button prev">←</button>
      <button class="carousel-button next">→</button>
      <div class="carousel-indicators"></div>
    </div> -->

    <!-- Single YouTube Video -->
    <!-- <div class="video-section">
      <h3>Demo Video</h3>
      <div class="video-container">
        <iframe
          width="560"
          height="315"
          src="https://www.youtube.com/embed/ysFav0b472w?si=Rxxp3R6_tkBXAEmP"
          title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          referrerpolicy="strict-origin-when-cross-origin"
          allowfullscreen
        ></iframe>
      </div>
    </div> -->

    <!-- YouTube Video List -->
    <!-- <div class="video-section">
      <h3>Demo Videos List</h3>
      <div class="video-container">
        <iframe
          width="560"
          height="315"
          src="https://www.youtube.com/embed/videoseries?si=Alenj7M9_gg7Xv49&amp;list=PL95lT3XlM14SgZHmmKn1mGSAAQc8ycq8v"
          title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          referrerpolicy="strict-origin-when-cross-origin"
          allowfullscreen
        ></iframe>
      </div>
    </div> -->

    <!-- Step 6 End: Add your paper results -->

    <!-- Step 7 Start: Add your paper conclusion -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <div class="content-section" id="conclusion">
      <h2>Conclusiones</h2>
      <p>TODO: Add Conclusion</p>
    </div>

    <!-- Step 7 End: Add your paper conclusion -->

    <!-- Step 8 Start: Add your paper references -->
    <div class="content-section" id="references">
      <h2>Referencias</h2>
      <p>Ardila, R., Branson, M., Davis, K., Kohler, M., Meyer, J., Henretty, M., Morais, R., Saunders, L., Tyers, F. M., and Weber, G. (2019). Common Voice: A massively-multilingual speech corpus. In Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020).

        VoxForge. (2025). Open speech corpus. Disponible en: https://www.voxforge.org

        Lingua Libre. (2025). Lingua Libre: Open collaborative project for multilingual speech recording. Disponible en: https://lingualibre.org

        Norman, D. A. (1988). The Psychology of Everyday Things. New York: Basic Books.

        Hartson, R., & Pyla, P. S. (2018). The UX Book: Agile UX Design for a Quality User Experience. Morgan Kaufmann.

        Hewett, Thomas & Baecker, Ronald & Card, Stuart & Carey, Tom & Gasen, Jean & Tremaine, Marilyn & Perlman, Gary & Strong, Gary & Verplank, William. (1992). ACM SIGCHI Curricula for Human-Computer Interaction. 10.1145/2594128. 

        R, Pushpakumar & Sanjaya, Karun & Rathika, S. & Alawadi, Ahmed & Makhzuna, Khamdamova & Venkatesh, S. & Rajalakshmi, B.. (2023). Human-Computer Interaction: Enhancing User Experience in Interactive Systems. E3S Web of Conferences. 399. 10.1051/e3sconf/202339904037.

        Issa, T., & Isaias, P. (2022). Sustainable Design: HCI, Usability and Environmental Concerns. Springer.
      </p>
    </div>
    <!-- 
    Please only edit below between CODE tags - TODOs
    Remove this step if not applicable
    -->

    <!-- <div class="bibtex-section" id="bibtex">
      <h2>BibTeX</h2>
      <button class="bibtex-copy-button" onclick="copyBibTeX()">
        Copy to Clipboard
      </button>
      <pre>
        <code class="language-bibtex">
          @inproceedings{TODO: YourPaperCitation,
            title={TODO: Paper Title},
            author={[TODO: Author Names]},
            booktitle={[TODO: Conference Name]},
            year={TODO: 2024},
            pages={[pages]}
          }
        </code>
      </pre>
    </div> -->

    <!-- Step 8 End: Add your paper references -->

    <!-- Step 9 Start: Add your paper acknowledgement -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <!-- <div class="content-section" id="acknowledgement">
      <h2>Acknowledgement</h2>
      <p>TODO: Add Acknowledgement if applicable or remove this</p>
    </div> -->

    <!-- Step 9 End: Add your paper acknowledgement -->

    <div class="footer">
      <!-- Step 10 Start: Edit footer -->
      <p>© 2024 [TODO: Add Name or University]. All rights reserved.</p>
      <!-- Step 10 End: Edit footer -->
      <!-- Please do not remove below code. -->
      <p>
        Website template free to borrow from
        <a
          href="https://github.com/indramal/iNdra-GitHub-Page-Template-For-Resarch"
          >here</a
        >.
      </p>
       <div>
          <!-- Please remove below code of page count or edit indragithubpagetemplate with your name. -->
    <img src="https://profile-counter.glitch.me/indragithubpagetemplate/count.svg" alt="Profile Counter">
</div>

    <!-- Do not edit below button -->
    <button class="scrollUpBtn" id="scrollUpBtn" onclick="scrollToTop()">
      ⬆
    </button>

    <script src="script.js"></script>
  </body>
</html>
